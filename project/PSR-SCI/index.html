<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="container">
        <header>
            <h1>Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement</h1>
            <div class="conference">@ ICLR 2025 Spotlight (Top 4.79%)</div>
            <div class="authors">
                <a href="https://navyzeng.github.io/" target="_blank">Haijin Zeng<sup>*1</sup></a>,
                <a href="https://SMARK2022.github.io/" target="_blank">Benteng Sun<sup>*2</sup></a>,
                <a href="https://cyyhit.github.io/" target="_blank">Yongyong Chen<sup>†2</sup></a>,
                <a href="https://openreview.net/profile?id=~Jingyong_Su3" target="_blank">Jingyong Su<sup>†2</sup></a>,
                <a href="https://teacher.nwpu.edu.cn/en/xuyong.html" target="_blank">Yong Xu<sup>2</sup></a>
            </div>

            <div class="affiliations">
                <sup>1</sup>Harvard University,
                <sup>2</sup>Harbin Institute of Technology (Shenzhen)<br>
                <sup>*</sup>Equal contribution,
                <sup>†</sup>Corresponding author
            </div>
            <div class="links">
                <a href="https://github.com/SMARK2022/PSR-SCI" class="link-button" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                        viewBox="0 0 16 16">
                        <path
                            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                    </svg>
                    GitHub
                </a>
                <a href="https://openreview.net/forum?id=Q150eWkQ4I" class="link-button" target="_blank">
                    <svg t="1747462275838" class="icon" viewBox="0 0 1024 1024" version="1.1"
                        xmlns="http://www.w3.org/2000/svg" p-id="3143" width="16" height="16">
                        <path
                            d="M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z"
                            fill="#444444" p-id="3144"></path>
                    </svg>
                    OpenReview
                </a>
                <a href="https://github.com/SMARK2022/PSR-SCI#citation" class="link-button" target="_blank">
                    <svg t="1747462332897" class="icon" viewBox="0 0 1024 1024" version="1.1"
                        xmlns="http://www.w3.org/2000/svg" p-id="4941" width="16" height="16">
                        <path
                            d="M961.28 320c0-106.24-85.76-192-192-192s-192 85.76-192 192a191.744 191.744 0 0 0 230.4 188.16C774.4 624.64 712.96 704 641.28 704c-35.2 0-64 28.8-64 64s28.8 64 64 64c176.64 0 320-200.32 320-448 0-12.8-1.28-24.96-2.56-37.12 0.64-8.96 2.56-17.92 2.56-26.88z m-704-192c-106.24 0-192 85.76-192 192a191.744 191.744 0 0 0 230.4 188.16C262.4 624.64 200.96 704 129.28 704c-35.2 0-64 28.8-64 64s28.8 64 64 64c176.64 0 320-200.32 320-448 0-12.8-1.28-24.96-2.56-37.12 0.64-8.96 2.56-17.92 2.56-26.88 0-106.24-86.4-192-192-192z"
                            p-id="4942"></path>
                    </svg>
                    Citation
                </a>
            </div>
        </header>

        <div class="tldr">
            <span class="tldr-header">TLDR</span>
            We propose a novel Predict-and-unmixing-driven Subspace Diffusion Refinement framework (PSR-SCI) for
            Spectral Compressive
            Imaging (SCI) reconstruction. Our method addresses the challenges of limited MSI training data and high
            computational cost of diffusion models for high-dimensional data, enabling efficient and high-quality MSI
            recovery.
        </div>

        <div class="teaser">
            <img src="images/teaser.png" alt="PSR-SCI Framework Overview" onerror="this.src='images/fig_teaser.png'">
        </div>

        <div class="section">
            <h2>Abstract</h2>
            <p>
                Spectral Compressive Imaging (SCI) reconstruction is inherently ill-posed, offering multiple plausible
                solutions from a single observation. Traditional deterministic methods typically struggle to effectively
                recover high-frequency details. Although diffusion models offer promising solutions to this challenge,
                their application is constrained by the limited training data and high computational demands associated
                with multispectral images (MSIs), complicating direct training. To address these issues, we propose a
                novel Predict-and-unmixing-driven-Subspace-Refine framework (PSR-SCI). This framework begins with a
                cost-effective predictor that produces an initial, rough estimate of the MSI. Subsequently, we introduce
                a unmixing-driven reversible spectral embedding module that decomposes the MSI into subspace images and
                spectral coefficients. This decomposition facilitates the adaptation of pre-trained RGB diffusion models
                and focuses refinement processes on high-frequency details, thereby enabling efficient diffusion
                generation with minimal MSI data. Additionally, we design a high-dimensional guidance mechanism with
                imaging consistency to enhance the model's efficacy. The refined subspace image is then reconstructed
                back into an MSI using the reversible embedding, yielding the final MSI with full spectral resolution.
                Experimental results on the standard KAIST and zero-shot datasets NTIRE, ICVL, and Harvard show that
                PSR-SCI enhances visual quality and delivers PSNR and SSIM metrics comparable to existing diffusion,
                transformer, and deep unfolding techniques. This framework provides a robust alternative to traditional
                deterministic SCI reconstruction methods. <a href="https://github.com/SMARK2022/PSR-SCI"
                    target="_blank">[Code and models]</a>
            </p>
        </div>

        <div class="section">
            <h2>Key Contributions</h2>
            <ul>
                <li><strong>(i)</strong> A spectral unmixing-driven predict-and-subspace refine strategy (PSR-SCI) for
                    SCI reconstruction that yields improved perceptual quality over deterministic methods and more
                    efficient enhancement than typical diffusion models.</li>
                <li><strong>(ii)</strong> A reversible decomposition module that utilizes hierarchical decomposition to
                    efficiently implement spectral subspace learning while maintaining high reversibility.</li>
                <li><strong>(iii)</strong> Focus on diffusion generation exclusively for high-frequency components,
                    accelerating fine-tuning and significantly reducing required training data.</li>
                <li><strong>(iv)</strong> High-dimensional guidance with SCI imaging consistency to enhance model
                    efficacy.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Related Works</h2>
            <p>
                The existing framework for SCI reconstruction predominantly consists of <em>model-based, Plug-and-Play,
                    End-to-end (E2E)</em>, and <em>Deep unfolding methods</em>.
            </p>
            <ul>
                <li><strong>Model-based methods</strong> depend on hand-crafted image priors but require manual
                    parameter tuning and have limited representation capacity.</li>
                <li><strong>Plug-and-play (PnP) algorithms</strong> incorporate pre-trained denoising networks into
                    traditional model-based methods but are limited by fixed pre-trained networks.</li>
                <li><strong>End-to-end (E2E) algorithms</strong> leverage CNNs to establish a mapping function but often
                    neglect fundamental principles of SCI systems.</li>
                <li><strong>Deep unfolding methods</strong> utilize multi-stage networks with interpretability through
                    explicit characterization of image priors.</li>
                <li><strong>Diffusion models</strong> - Recent works like DiffSCI utilize pre-trained denoising
                    diffusion models for RGB images as the denoiser within the PnP framework.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Method: PSR-SCI Framework</h2>
            <div class="figure">
                <img src="images/pipeline.png" alt="PSR-SCI Pipeline">
                <div class="caption">
                    <strong>Figure:</strong> PSR-SCI comprises (a) fast predictor with frequency splitting, (b)
                    unmixing-based
                    reversible embedding, and (c) subspace refinement via pretrained diffusion.
                </div>
            </div>

            <h3>1. Snapshot Compressive Imaging and Problem Setup</h3>
            <p>
                In a CASSI system, an MSI \( \mathcal{X} \in \mathbb{R}^{H \times W \times B} \) is projected into a 2D
                measurement \( \mathcal{Y} \in \mathbb{R}^{H \times (W + d(B-1))} \) via coded spectral modulation. The
                imaging
                model can be formulated as:
                \[ \mathbf{y} = \mathbf{\Phi} \mathbf{x} + \mathbf{n}, \]
                where \( \mathbf{\Phi} \) encodes spectral-shifted masks, and \( \mathbf{x} \) is the vectorized MSI.
                Reconstructing \( \mathbf{x} \) from \( \mathbf{y} \) is ill-posed and benefits from strong generative
                priors.
            </p>

            <h3>2. Predict-and-Subspace-Refine Framework</h3>
            <p>
                We first estimate a coarse MSI \( \mathcal{X}_{\textit{init}} = \phi(\mathcal{Y}) \) via a trained
                predictor. Then, a learnable
                frequency separator \( \tau \) splits it into high- and low-frequency parts: \( (\mathcal{X}^h,
                \mathcal{X}^l) =
                \tau(\mathcal{X}_{\textit{init}}) \). The high-frequency part is embedded into subspace form:
                \[ (\mathcal{A}^h, E) = \psi(\mathcal{X}^h), \]
                where \( \mathcal{A}^h \) is a low-rank abundance map and \( E \) encodes spectral coefficients. This
                enables refinement
                via diffusion on \( \mathcal{A}^h \), with final MSI recovered as:
                \[ \hat{\mathcal{X}} = \psi^{-1}(\mathcal{A}^h_{\textit{diff}}, E) + \mathcal{X}^l. \]
            </p>

            <h3>3. Reversible Spectral Embedding (URSe)</h3>
            <p>
                The URSe module implements invertible unmixing via hierarchical convolutions and spectral attention,
                ensuring
                minimal information loss. Unlike direct compression, URSe guarantees structural recovery of the MSI from
                latent
                subspace.
            </p>

            <h3>4. Diffusion Refinement with High-Dimensional Guidance</h3>
            <p>
                We adapt pretrained Stable Diffusion (2.1-base) for subspace refinement. A parallel encoder allows
                tuning on
                small MSI datasets. To enforce measurement consistency, we introduce a high-dimensional guidance loss:
                \[ \mathcal{L} = \|\mathcal{Y} -
                \Phi(\psi^{-1}(\mathcal{D}(\hat{\mathcal{z}}_0), E) + \mathcal{X}^l) \|^2. \]
                This forms a guided reverse SDE that jointly optimizes perceptual quality and physical realism.
            </p>
        </div>

        <div class="section">
            <h2>Experimental Results</h2>

            <h3>Quantitative Evaluation</h3>
            <div class="results-table">
                <div class="table-caption"></div>
                <strong>Table 1:</strong> Numerical evaluations between our PSR-SCI and state-of-the-art methods across
                10 simulated scenes. The best results are in <span class="best">bold</span> and second-best are <span
                    class="second-best">underlined</span>.
            </div>
            <div class="table-responsive">
                <table class="data-table">
                    <thead style="background-color: #d3d3d3;">
                        <tr>
                            <th>Algorithms</th>
                            <th>Category</th>
                            <th>Reference</th>
                            <th>Average PSNR/SSIM</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- Traditional Methods -->
                        <tr style="background-color: #f2f2f2;">
                            <td>DeSCI</td>
                            <td>Model</td>
                            <td>TPAMI 2019</td>
                            <td>25.27 / 0.748</td>
                        </tr>

                        <!-- CNN-based Methods -->
                        <tr style="background-color: #ffdddd;">
                            <td>\(\lambda\)-Net</td>
                            <td>CNN</td>
                            <td>ICCV 2019</td>
                            <td>28.53 / 0.841</td>
                        </tr>
                        <tr style="background-color: #ffdddd;">
                            <td>TSA-Net</td>
                            <td>CNN</td>
                            <td>ECCV 2020</td>
                            <td>31.35 / 0.895</td>
                        </tr>

                        <!-- Transformer-based Methods -->
                        <tr style="background-color: #ffdddd;">
                            <td>HDNet</td>
                            <td>Transformer</td>
                            <td>CVPR 2022</td>
                            <td>34.66 / 0.946</td>
                        </tr>
                        <tr style="background-color: #ffdddd;">
                            <td>MST++</td>
                            <td>Transformer</td>
                            <td>CVPR 2022</td>
                            <td>35.72 / 0.955</td>
                        </tr>

                        <!-- Deep Unfolding Methods -->
                        <tr style="background-color: #ffffdd;">
                            <td>DAUHST-3stg</td>
                            <td>Deep Unfolding</td>
                            <td>NeurIPS 2022</td>
                            <td>37.21 / 0.959</td>
                        </tr>

                        <!-- Diffusion and Our Methods -->
                        <tr style="background-color: #ddffdd;">
                            <td>DAUHST-SP2</td>
                            <td>Subspace prior</td>
                            <td>Information Fusion 2024</td>
                            <td><span class="second-best">37.61 / 0.966</span></td>
                        </tr>
                        <tr style="background-color: #ddffdd;">
                            <td>DiffSCI</td>
                            <td>Diffusion</td>
                            <td>CVPR 2024</td>
                            <td>35.28 / 0.916</td>
                        </tr>
                        <tr style="background-color: #ddffdd;">
                            <td><strong>PSR-SCI-T</strong></td>
                            <td>Diffusion</td>
                            <td>ICLR 2025 (Ours)</td>
                            <td>36.68 / 0.961</td>
                        </tr>
                        <tr style="background-color: #ddffdd;">
                            <td><strong>PSR-SCI-D</strong></td>
                            <td>Diffusion</td>
                            <td>ICLR 2025 (Ours)</td>
                            <td><span class="best">38.14 / 0.967</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <p>
            Our PSR-SCI-D model achieves state-of-the-art performance across all metrics on the KAIST dataset, with an
            average PSNR of 38.14dB and SSIM of 0.967 - an improvement of nearly 1.4dB compared to leading
            diffusion-based methods. The PSR-SCI-T variant also demonstrates competitive performance, highlighting the
            effectiveness of our approach.
        </p>
        </tr>

        <h3>Qualitative Results</h3>
        <div class="figure">
            <img src="images/simulation_results.png" alt="Simulation Results"
                onerror="this.src='https://via.placeholder.com/800x400?text=Simulation+Results'">
            <div class="caption">
                <strong>Figure 2:</strong> Visual comparison on the KAIST dataset. Our method yields superior visual
                effects with cleaner textures and fewer artifacts compared to other state-of-the-art methods.
            </div>
        </div>

        <div class="figure">
            <img src="images/real_dataset.png" alt="Real Dataset Results"
                onerror="this.src='https://via.placeholder.com/800x300?text=Real+Dataset+Results'">
            <div class="caption">
                <strong>Figure 3:</strong> Visual comparison on a real dataset. PSR-SCI recovers more complete and
                detailed shapes with fewer artifacts compared to other methods.
            </div>
        </div>

        <h3>Zero-Shot Generalization</h3>
        <div class="figure">
            <img src="images/zero_shot.jpg" alt="Zero-Shot Results"
                onerror="this.src='https://via.placeholder.com/800x300?text=Zero-Shot+Results'">
            <div class="caption">
                <strong>Figure 4:</strong> Generalization performance on zero-shot datasets (ICVL, NTIRE, Harvard). Our
                model consistently outperforms competing methods in both PSNR and perceptual metrics.
            </div>
        </div>

        <h3>Computational Efficiency</h3>
        <p>
            Our PSR-SCI model significantly reduces the computational burden, requiring only 8.9 seconds for 50 sampling
            steps compared to 85 seconds for state-of-the-art diffusion-based methods, while achieving superior
            performance.
        </p>

        <div class="section">
            <h2>Conclusion</h2>
            <p>
                We introduced a new framework for spectral compressive imaging reconstruction that focuses on
                reconstructing
                high-frequency details by fine-tuning a diffusion model pre-trained on large-scale RGB images. Our
                empirical
                results demonstrate significant improvements in detail quality and superior metrics compared to current
                state-of-the-art methods. We believe that our work introduces a novel direction in spectral compressive
                imaging
                reconstruction and establishes a robust benchmark for future research.
            </p>
        </div>

        <div class="section">
            <h2>Citation</h2>
            <div class="citation-container">
                <button class="copy-button" onclick="copyCitation()">
                    <svg t="1747462668534" class="icon" viewBox="0 0 1024 1024" version="1.1"
                        xmlns="http://www.w3.org/2000/svg" p-id="8667" width="16" height="16">
                        <path
                            d="M672 832 224 832c-52.928 0-96-43.072-96-96L128 160c0-52.928 43.072-96 96-96l448 0c52.928 0 96 43.072 96 96l0 576C768 788.928 724.928 832 672 832zM224 128C206.368 128 192 142.368 192 160l0 576c0 17.664 14.368 32 32 32l448 0c17.664 0 32-14.336 32-32L704 160c0-17.632-14.336-32-32-32L224 128z"
                            fill="#5E6570" p-id="8668"></path>
                        <path
                            d="M800 960 320 960c-17.664 0-32-14.304-32-32s14.336-32 32-32l480 0c17.664 0 32-14.336 32-32L832 256c0-17.664 14.304-32 32-32s32 14.336 32 32l0 608C896 916.928 852.928 960 800 960z"
                            fill="#5E6570" p-id="8669"></path>
                        <path
                            d="M544 320 288 320c-17.664 0-32-14.336-32-32s14.336-32 32-32l256 0c17.696 0 32 14.336 32 32S561.696 320 544 320z"
                            fill="#5E6570" p-id="8670"></path>
                        <path
                            d="M608 480 288.032 480c-17.664 0-32-14.336-32-32s14.336-32 32-32L608 416c17.696 0 32 14.336 32 32S625.696 480 608 480z"
                            fill="#5E6570" p-id="8671"></path>
                        <path
                            d="M608 640 288 640c-17.664 0-32-14.304-32-32s14.336-32 32-32l320 0c17.696 0 32 14.304 32 32S625.696 640 608 640z"
                            fill="#5E6570" p-id="8672"></path>
                    </svg>
                    Copy
                </button>
                <pre id="citation-text">
@inproceedings{zeng2025spectral,
title={Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement},
author={Zeng, Haijin and Sun, Benteng and Chen, Yongyong and Su, Jingyong and Xu, Yong},
booktitle={The Thirteenth International Conference on Learning Representations}
    year={2025}
}
                </pre>
            </div>
        </div>


        <script>
            function copyCitation() {
                const text = document.getElementById('citation-text').textContent;
                navigator.clipboard.writeText(text).then(() => {
                    const button = document.querySelector('.copy-button');
                    button.classList.add('copied');
                    button.innerHTML = '<svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M20 6L9 17L4 12"/></svg>Copied!';
                    setTimeout(() => {
                        button.classList.remove('copied');
                        button.innerHTML = '<svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M16 1H4C2.9 1 2 1.9 2 3V17H4V3H16V1ZM19 5H8C6.9 5 6 5.9 6 7V21C6 22.1 6.9 23 8 23H19C20.1 23 21 22.1 21 21V7C21 5.9 20.1 5 19 5ZM19 21H8V7H19V21Z"/></svg>Copy';
                    }, 2000);
                });
            }
        </script>

    </div>
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>

</html>